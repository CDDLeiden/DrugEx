{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e550ab92-5f0f-45c9-a34b-c69437268441",
   "metadata": {},
   "source": [
    "# Data Sets\n",
    "\n",
    "You have to preprocess the data depending on the model you want to build. You can refer to the particular sections relevant for your model of interest:\n",
    "\n",
    "1. [Graph-Based Transformer](#Preparing-Data-for-the-Graph-Based-Transformer)\n",
    "2. [Smiles-Based Transformer](#Preparing-Data-for-the-Smiles-Based-Transformer)\n",
    "\n",
    "In this tutorial, we assume you already extracted a list of SMILES strings that you want to use either for pretraining or finetuning. You can download the example data file [here]() and extract the molecules with `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2801d9b5-49bc-4200-8010-9eec1f1fa803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    CCCCn1cc2c(nc(NC(=O)Nc3ccc(cc3)S(=O)(=O)O)n4nc...\n",
      "1    CCCCn1cc2c(nc(NC(=O)Nc3ccc(cc3)S(=O)(=O)O)n4nc...\n",
      "2    NC1=Nc2c(cnn2CCN3CCC(CC3)N4CCOCC4)C5=NN(Cc6ccc...\n",
      "3        CCN1C(=O)N(CC)c2nc3N(CCc4ccccc4OC)CCCn3c2C1=O\n",
      "4    COc1cncc(c1)c2cc(NC(=O)CN3CCOCC3)nc(n2)n4nc(C)...\n",
      "Name: CANONICAL_SMILES, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11464,)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "smiles = pd.read_csv('data/A2AR_raw.txt', sep='\\t', header=0, usecols=('CANONICAL_SMILES',), na_values=('NA', 'nan', 'NaN')).iloc[:,0]\n",
    "smiles.dropna(inplace=True)\n",
    "\n",
    "print(smiles.head())\n",
    "smiles.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78e8199-c5bc-48db-ad2f-d5859d7e79ad",
   "metadata": {},
   "source": [
    "These will be our molecules of interest and further in the tutorial we will use them for [finetuning existing DrugEx models](finetuning.ipynb). Therefore, now we have to create the proper data sets for this task. However, before we do that these molecules have to be standardized. That is easily accomplised with the `Standardization` processor that we can apply to our compounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c901b01-be89-480c-9209-761cdd24cb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sichom/software/miniconda/envs/drugex/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Parsing Error: [V+8]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sichom/projects/DrugEx/drugex/molecules/converters/standardizers.py\", line 58, in __call__\n",
      "    raise StandardizationException(f\"No carbon in SMILES: {smileR}\")\n",
      "drugex.molecules.converters.standardizers.StandardizationException: No carbon in SMILES: [V+8]\n",
      "WARNING:root:An exception occurred when converting molecule data: [Na+].[Na+].[Na+].[O-][V](=O)([O-])[O-]\n",
      " Cause: <class 'drugex.molecules.converters.standardizers.StandardizationException'>: No carbon in SMILES: [V+8]\n",
      "ERROR:root:Parsing Error: [V+8]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sichom/projects/DrugEx/drugex/molecules/converters/standardizers.py\", line 58, in __call__\n",
      "    raise StandardizationException(f\"No carbon in SMILES: {smileR}\")\n",
      "drugex.molecules.converters.standardizers.StandardizationException: No carbon in SMILES: [V+8]\n",
      "WARNING:root:An exception occurred when converting molecule data: [Na+].[Na+].[Na+].[O-][V](=O)([O-])[O-]\n",
      " Cause: <class 'drugex.molecules.converters.standardizers.StandardizationException'>: No carbon in SMILES: [V+8]\n",
      "ERROR:root:Parsing Error: [Zn+2]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sichom/projects/DrugEx/drugex/molecules/converters/standardizers.py\", line 58, in __call__\n",
      "    raise StandardizationException(f\"No carbon in SMILES: {smileR}\")\n",
      "drugex.molecules.converters.standardizers.StandardizationException: No carbon in SMILES: [Zn+2]\n",
      "WARNING:root:An exception occurred when converting molecule data: [Cl-].[Cl-].[Zn+2]\n",
      " Cause: <class 'drugex.molecules.converters.standardizers.StandardizationException'>: No carbon in SMILES: [Zn+2]\n",
      "ERROR:root:Parsing Error: [Zn+2]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sichom/projects/DrugEx/drugex/molecules/converters/standardizers.py\", line 58, in __call__\n",
      "    raise StandardizationException(f\"No carbon in SMILES: {smileR}\")\n",
      "drugex.molecules.converters.standardizers.StandardizationException: No carbon in SMILES: [Zn+2]\n",
      "WARNING:root:An exception occurred when converting molecule data: [Cl-].[Cl-].[Zn+2]\n",
      " Cause: <class 'drugex.molecules.converters.standardizers.StandardizationException'>: No carbon in SMILES: [Zn+2]\n",
      "Parsing Error: NN\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sichom/projects/DrugEx/drugex/molecules/converters/standardizers.py\", line 58, in __call__\n",
      "    raise StandardizationException(f\"No carbon in SMILES: {smileR}\")\n",
      "drugex.molecules.converters.standardizers.StandardizationException: No carbon in SMILES: NN\n",
      "WARNING:root:An exception occurred when converting molecule data: NN\n",
      " Cause: <class 'drugex.molecules.converters.standardizers.StandardizationException'>: No carbon in SMILES: NN\n",
      "ERROR:root:Parsing Error: NN\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sichom/projects/DrugEx/drugex/molecules/converters/standardizers.py\", line 58, in __call__\n",
      "    raise StandardizationException(f\"No carbon in SMILES: {smileR}\")\n",
      "drugex.molecules.converters.standardizers.StandardizationException: No carbon in SMILES: NN\n",
      "WARNING:root:An exception occurred when converting molecule data: NN\n",
      " Cause: <class 'drugex.molecules.converters.standardizers.StandardizationException'>: No carbon in SMILES: NN\n",
      "Parsing Error: O=[As]O\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sichom/projects/DrugEx/drugex/molecules/converters/standardizers.py\", line 58, in __call__\n",
      "    raise StandardizationException(f\"No carbon in SMILES: {smileR}\")\n",
      "drugex.molecules.converters.standardizers.StandardizationException: No carbon in SMILES: O=[As]O\n",
      "WARNING:root:An exception occurred when converting molecule data: [Na+].[O-][As]=O\n",
      " Cause: <class 'drugex.molecules.converters.standardizers.StandardizationException'>: No carbon in SMILES: O=[As]O\n",
      "ERROR:root:Parsing Error: O=[As]O\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sichom/projects/DrugEx/drugex/molecules/converters/standardizers.py\", line 58, in __call__\n",
      "    raise StandardizationException(f\"No carbon in SMILES: {smileR}\")\n",
      "drugex.molecules.converters.standardizers.StandardizationException: No carbon in SMILES: O=[As]O\n",
      "WARNING:root:An exception occurred when converting molecule data: [Na+].[O-][As]=O\n",
      " Cause: <class 'drugex.molecules.converters.standardizers.StandardizationException'>: No carbon in SMILES: O=[As]O\n",
      "ERROR:root:Parsing Error: [Sn+2]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sichom/projects/DrugEx/drugex/molecules/converters/standardizers.py\", line 58, in __call__\n",
      "    raise StandardizationException(f\"No carbon in SMILES: {smileR}\")\n",
      "drugex.molecules.converters.standardizers.StandardizationException: No carbon in SMILES: [Sn+2]\n",
      "WARNING:root:An exception occurred when converting molecule data: F[Sn]F\n",
      " Cause: <class 'drugex.molecules.converters.standardizers.StandardizationException'>: No carbon in SMILES: [Sn+2]\n",
      "ERROR:root:Parsing Error: [Sn+2]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sichom/projects/DrugEx/drugex/molecules/converters/standardizers.py\", line 58, in __call__\n",
      "    raise StandardizationException(f\"No carbon in SMILES: {smileR}\")\n",
      "drugex.molecules.converters.standardizers.StandardizationException: No carbon in SMILES: [Sn+2]\n",
      "WARNING:root:An exception occurred when converting molecule data: F[Sn]F\n",
      " Cause: <class 'drugex.molecules.converters.standardizers.StandardizationException'>: No carbon in SMILES: [Sn+2]\n",
      "ERROR:root:Parsing Error: O\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sichom/projects/DrugEx/drugex/molecules/converters/standardizers.py\", line 58, in __call__\n",
      "    raise StandardizationException(f\"No carbon in SMILES: {smileR}\")\n",
      "drugex.molecules.converters.standardizers.StandardizationException: No carbon in SMILES: O\n",
      "WARNING:root:An exception occurred when converting molecule data: O.O.O.O.O.O.[Cl-].[Cl-].[Sr+2]\n",
      " Cause: <class 'drugex.molecules.converters.standardizers.StandardizationException'>: No carbon in SMILES: O\n",
      "ERROR:root:Parsing Error: O\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/sichom/projects/DrugEx/drugex/molecules/converters/standardizers.py\", line 58, in __call__\n",
      "    raise StandardizationException(f\"No carbon in SMILES: {smileR}\")\n",
      "drugex.molecules.converters.standardizers.StandardizationException: No carbon in SMILES: O\n",
      "WARNING:root:An exception occurred when converting molecule data: O.O.O.O.O.O.[Cl-].[Cl-].[Sr+2]\n",
      " Cause: <class 'drugex.molecules.converters.standardizers.StandardizationException'>: No carbon in SMILES: O\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7958"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from drugex.datasets.processing import Standardization\n",
    "\n",
    "N_PROC = 4 # standardization (like many tasks in this tutorial) can be done in parallel so we save the desired number of CPUs to use here\n",
    "standardizer = Standardization(n_proc=N_PROC)\n",
    "smiles = standardizer.apply(smiles)\n",
    "\n",
    "len(smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f8b6c9-dc5e-4134-8d5f-bd39c92f8ccf",
   "metadata": {},
   "source": [
    "The standardizer also handles duplicates for us so the resulting number of molecules is reduced in comparison to the original data. Some strange molecules also failed to parse and DrugEx prints out a warning if that happens.\n",
    "\n",
    "## Preparing Data for the Graph-Based Transformer\n",
    "\n",
    "The input for the transformer model are the fragments that the molecules of interest are made up of while the molcules of interest themselves are the output. You can use the `FragmentEncoder` processor in combination with the `GraphFragmentEncoder` to generate your data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75b91a7f-9cf9-4b35-827f-e9abd8892f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from drugex.datasets.processing import FragmentEncoder\n",
    "from drugex.datasets.fragments import GraphFragmentEncoder, FragmentPairsSplitter\n",
    "from drugex.molecules.converters.fragmenters import Fragmenter\n",
    "from drugex.corpus.vocabulary import VocGraph\n",
    "\n",
    "encoder = FragmentEncoder(\n",
    "    fragmenter=Fragmenter(4, 4, 'brics'), # handles how fragment-molecule pairs are created\n",
    "    encoder=GraphFragmentEncoder(\n",
    "        VocGraph(n_frags=4) # encoder uses the graph vocabulary to create the graph matrix from the fragment-molecule pairs (see: https://chemrxiv.org/engage/api-gateway/chemrxiv/assets/orp/resource/item/61aa8b58bc299c0b30887f80/original/drug-ex-v3-scaffold-constrained-drug-design-with-graph-transformer-based-reinforcement-learning.pdf)\n",
    "    ),\n",
    "    pairs_splitter=FragmentPairsSplitter(0.1, 100, unique_only=True), # in this instance, we also use a splitter to divide the fragment-molecule pairs into a test set and training set\n",
    "    n_proc=N_PROC # we can again run these actions in parallel\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82111a82-52f7-4d43-98ec-bc73e39b5730",
   "metadata": {},
   "source": [
    "When we have defined the encoder, we can just apply it on our data and use a `GraphDataSet` to collect the results. Depending on the output of the splitter, the `FragmentEncoder` creates one data set per split. Above we specified `unique_only=True` in the splitter definition, which means we will be able to collect a training set of only unique fragment-molecule combinations and a randomly chosen test set of fragment-molecule pairs. The splitter returns the test set first and then the training set. Therefore, we will have to collect the results in that order. We create the empty data sets first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "019359d9-6788-4145-bae2-6a496a1b11c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from drugex.logs import logger\n",
    "import logging\n",
    "\n",
    "logger.setLevel(logging.ERROR) # remove warnings from the drugex logger to reduce the amount of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3c1ed13-fbbf-468a-9f6c-7f43a23aac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from drugex.datasets.processing import GraphFragDataSet\n",
    "import os\n",
    "\n",
    "# create the directory for our input files\n",
    "graph_input_folder = \"data/inputs/graph\"\n",
    "if not os.path.exists(graph_input_folder):\n",
    "    os.makedirs(graph_input_folder)\n",
    "\n",
    "# create empty data sets (we can specify a path to a file where the data set can be saved)\n",
    "train = GraphFragDataSet(f\"{graph_input_folder}/train.txt\")\n",
    "test = GraphFragDataSet(f\"{graph_input_folder}/test.txt\")\n",
    "\n",
    "# apply the encoder and collect data (test data is collected first)\n",
    "encoder.apply(smiles, encodingCollectors=[test, train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31484731-88b0-4d1d-8716-6a557437e963",
   "metadata": {},
   "source": [
    "Now the data sets are ready and we can save them to their destination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d939580-4f64-446f-803c-e5c9d8ce6c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.save()\n",
    "test.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d74193-9417-47ed-9329-212f3a2c0048",
   "metadata": {},
   "source": [
    "You can check that the appropriate files were indeed created in the `data/inputs/graph/` folder. We can easily recreate the `GraphFragDataSet` instances from these files when we need them for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "407c2ec6-1043-453f-abfb-78fe991d0d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C0</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>C8</th>\n",
       "      <th>C9</th>\n",
       "      <th>...</th>\n",
       "      <th>C390</th>\n",
       "      <th>C391</th>\n",
       "      <th>C392</th>\n",
       "      <th>C393</th>\n",
       "      <th>C394</th>\n",
       "      <th>C395</th>\n",
       "      <th>C396</th>\n",
       "      <th>C397</th>\n",
       "      <th>C398</th>\n",
       "      <th>C399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   C0  C1  C2  C3  C4  C5  C6  C7  C8  C9  ...  C390  C391  C392  C393  C394  \\\n",
       "0   1   0   0   0   1   5   0   0   0   1  ...     0     0     0     0     0   \n",
       "1   1   0   0   0   1  18   0   0   0   1  ...     0     0     0     0     0   \n",
       "2   1   0   0   0   1   5   0   0   0   1  ...     0     0     0     0     0   \n",
       "3   1   0   0   0   1   5   0   0   0   1  ...     0     0     0     0     0   \n",
       "4   1   0   0   0   1   5   0   0   0   1  ...     0     0     0     0     0   \n",
       "\n",
       "   C395  C396  C397  C398  C399  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     0     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 400 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_from_file = GraphFragDataSet('imported')\n",
    "train_from_file.fromFile(train.outpath)\n",
    "\n",
    "# we can check the output by converting the data set to a pandas DataFrame\n",
    "df = train_from_file.getDataFrame()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ad3a22-de35-45e2-9ca7-3f7ee74cbc03",
   "metadata": {},
   "source": [
    "It is also a good idea to save the used vocabulary along with the files for future reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a269152-515e-420e-a500-f1c19a09565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.getVoc().toFile(f\"{graph_input_folder}/vocabulary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76ee0b3-8463-4b93-b3d9-0caaf53505af",
   "metadata": {},
   "source": [
    "## Preparing Data for the Smiles-Based Transformer\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1a42c5-4776-4085-a0ee-8b9708dce99b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
